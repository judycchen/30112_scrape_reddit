{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba300b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794ac006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/apple/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/apple/Desktop/30112_python/Scrape_Reddit/scraped_data/reddit_inflation_2020_2025_posts_and_comments_TEST_clean.parquet\n",
      "Loaded shape: (35023, 10)\n"
     ]
    }
   ],
   "source": [
    "# Basic paths\n",
    "\n",
    "# If needed in a fresh environment, run once:\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# ---------- Paths ----------\n",
    "base_path = Path(\"/Users/apple/Desktop/30112_python/Scrape_Reddit\")\n",
    "cleaned_dir = base_path / \"scraped_data\"\n",
    "\n",
    "in_path = cleaned_dir / \"reddit_inflation_2020_2025_posts_and_comments_TEST_clean.parquet\"\n",
    "\n",
    "print(\"Loading:\", in_path)\n",
    "df = pd.read_parquet(in_path)\n",
    "print(\"Loaded shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0055bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase counts:\n",
      "phase_temp\n",
      "early    35023\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create Phase Labels\n",
    "# These are temporary for now\n",
    "\n",
    "def assign_temp_phase(dt: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Temporary phase definition based on year only.\n",
    "    Replace later with CPI + policy-based phases.\n",
    "    \"\"\"\n",
    "    if pd.isna(dt):\n",
    "        return \"unknown\"\n",
    "\n",
    "    year = dt.year\n",
    "    if year <= 2021:\n",
    "        return \"early\"\n",
    "    elif year == 2022:\n",
    "        return \"peak\"\n",
    "    else:\n",
    "        return \"post\"\n",
    "\n",
    "# Ensure created_utc is datetime\n",
    "if not pd.api.types.is_datetime64_any_dtype(df[\"created_utc\"]):\n",
    "    df[\"created_utc\"] = pd.to_datetime(df[\"created_utc\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "df[\"phase_temp\"] = df[\"created_utc\"].apply(assign_temp_phase)\n",
    "\n",
    "print(\"Phase counts:\")\n",
    "print(df[\"phase_temp\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53304818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword List and helper for is_inflation\n",
    "\n",
    "KEYWORDS = [\n",
    "    # Core inflation/econ\n",
    "    \"inflation\",\n",
    "    \"cost of living\",\n",
    "    \"cost-of-living\",\n",
    "    \"high cost of living\",\n",
    "    \"living costs\",\n",
    "    \"price increases\",\n",
    "    \"rising prices\",\n",
    "    \"cpi\",\n",
    "    \"consumer price index\",\n",
    "    \"interest rates\",\n",
    "    \"mortgage rates\",\n",
    "    \"fed\",\n",
    "    \"federal reserve\",\n",
    "    \"rate hike\",\n",
    "    \"rate hikes\",\n",
    "    \"rate increase\",\n",
    "    \"rate increases\",\n",
    "    # Everyday expenses\n",
    "    \"gas prices\",\n",
    "    \"gas price\",\n",
    "    \"grocery prices\",\n",
    "    \"grocery bill\",\n",
    "    \"food prices\",\n",
    "    \"food bill\",\n",
    "    \"rent increase\",\n",
    "    \"rent hike\",\n",
    "    \"higher rent\",\n",
    "    \"rent is too high\",\n",
    "    \"housing costs\",\n",
    "    \"housing affordability\",\n",
    "    \"property taxes\",\n",
    "    \"electric bill\",\n",
    "    \"electricity bill\",\n",
    "    \"energy bill\",\n",
    "    \"heating bill\",\n",
    "    \"gas bill\",\n",
    "    \"utility bills\",\n",
    "    \"utilities\",\n",
    "    # Income / strain\n",
    "    \"wage stagnation\",\n",
    "    \"wages not keeping up\",\n",
    "    \"real wages\",\n",
    "    \"paycheck to paycheck\",\n",
    "    \"making ends meet\",\n",
    "    \"can't afford\",\n",
    "    \"cannot afford\",\n",
    "]\n",
    "KEYWORDS_LOWER = [k.lower() for k in KEYWORDS]\n",
    "\n",
    "def text_matches_keywords(text: str) -> bool:\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    t = text.lower()\n",
    "    return any(k in t for k in KEYWORDS_LOWER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b3133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_inflation value counts:\n",
      "is_inflation\n",
      "False    24269\n",
      "True     10754\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample inflation-related rows:\n",
      "----\n",
      "1970-01-01 00:00:01.641470158+00:00 | personalfinance | comment\n",
      "If he pays 1680 by splitting everything, and only 550 if he doesn't pay half of taxes, it doesn't feel fair here. In another comment thread on this post it was figured that the taxes in this case are 67% of overall expenses. If I was moving someone in and they wanted me to pay almost $3k/mo while they pay around 500 and we make the same or they make a bit more, I would not move that person in. I'd ...\n",
      "\n",
      "----\n",
      "1970-01-01 00:00:01.643577614+00:00 | personalfinance | comment\n",
      "I know an elderly person that got a call just like that. Like your great aunt and uncle, luckily one of their kids was visiting. The line, \"Let me put my son on, he is a federal agent\" got the scammer to hang up *real* quick. ...\n",
      "\n",
      "----\n",
      "1970-01-01 00:00:01.642356762+00:00 | personalfinance | comment\n",
      "Separate accounts. \n",
      "\n",
      "I pay house, utilities, most repairs, going out money, etc.\n",
      "\n",
      "She pays insurance, equipment/vehicle payments, groceries, etc. ...\n",
      "\n",
      "----\n",
      "1970-01-01 00:00:01.641003720+00:00 | personalfinance | comment\n",
      "This. And with this the consideration is will that 30 minutes each way equal spending considerably more because OP no longer has that time.\n",
      "\n",
      "I.e. will less time to cook = picking up more convenience or fast food? That can very quickly exceed any monetary gains from higher salary.\n",
      "\n",
      "How old is the vehicle used to commute.   I know from first hand experience that increasing mileage  considerably can  ...\n",
      "\n",
      "----\n",
      "1970-01-01 00:00:01.641161635+00:00 | personalfinance | comment\n",
      "I have worked for a solar company and a solar financing company. There are very few situations where these actually paid off. These were customers with high electric bills usually due to pools or other heavy use equipment paired with absolute security that they would be in the home for 15 plus years to actually see a cost benefit. This was when premium solar was costing $4 plus per watt. \n",
      "\n",
      "For man ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Build raw_text (fallback) and recompute is_inflation\n",
    "\n",
    "# raw_text should already exist from the cleaning step (title + body).\n",
    "# If not, create it here.\n",
    "if \"raw_text\" not in df.columns:\n",
    "    df[\"raw_text\"] = (\n",
    "        df[[\"title\", \"body\"]]\n",
    "        .fillna(\"\")\n",
    "        .agg(\" \".join, axis=1)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "df[\"is_inflation\"] = df[\"raw_text\"].apply(text_matches_keywords)\n",
    "\n",
    "print(\"is_inflation value counts:\")\n",
    "print(df[\"is_inflation\"].value_counts(dropna=False))\n",
    "\n",
    "# Manual quality check: print a few examples\n",
    "print(\"\\nSample inflation-related rows:\")\n",
    "if df[\"is_inflation\"].any():\n",
    "    sample_infl = df[df[\"is_inflation\"]].sample(\n",
    "        n=min(5, df[\"is_inflation\"].sum()), random_state=42\n",
    "    )\n",
    "    for _, row in sample_infl.iterrows():\n",
    "        print(\"----\")\n",
    "        print(row[\"created_utc\"], \"|\", row[\"subreddit\"], \"|\", row[\"type\"])\n",
    "        print(row[\"raw_text\"][:400], \"...\\n\")\n",
    "else:\n",
    "    print(\"No rows flagged as inflation-related in this TEST dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcf3523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inflation-related rows: 10754\n"
     ]
    }
   ],
   "source": [
    "# Pilot analysis (on TEST data)\n",
    "\n",
    "df_inf = df[df[\"is_inflation\"]].copy()\n",
    "print(\"\\nInflation-related rows:\", df_inf.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8335d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monthly counts (first 10 rows):\n",
      "type     comment  submission\n",
      "month                       \n",
      "1970-01     9535        1219\n",
      "\n",
      "Counts by phase and type:\n",
      "type        comment  submission\n",
      "phase_temp                     \n",
      "early          9535        1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/k_ksjzq515d486qysdmsnrlr0000gn/T/ipykernel_36360/1513002359.py:6: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  .groupby([df_inf[\"created_utc\"].dt.to_period(\"M\"), \"type\"])\n"
     ]
    }
   ],
   "source": [
    "if not df_inf.empty:\n",
    "    # Group inflation-related rows by month (period 'M') and post type,\n",
    "    # count how many rows fall into each (month, type) combo.\n",
    "    monthly_counts = (\n",
    "        df_inf\n",
    "        .groupby([df_inf[\"created_utc\"].dt.to_period(\"M\"), \"type\"])\n",
    "        .size()                      # number of rows in each group\n",
    "        .unstack(fill_value=0)       # turn 'type' into columns\n",
    "        .rename_axis(index=\"month\")  # label the index as 'month'\n",
    "    )\n",
    "\n",
    "    print(\"\\nMonthly counts (first 10 rows):\")\n",
    "    print(monthly_counts.head(10))\n",
    "\n",
    "    # Group by phase and type to see how many posts/comments per phase.\n",
    "    phase_counts = (\n",
    "        df_inf\n",
    "        .groupby([\"phase_temp\", \"type\"])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "\n",
    "    print(\"\\nCounts by phase and type:\")\n",
    "    print(phase_counts)\n",
    "else:\n",
    "    print(\"No inflation-related rows; skipping counts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795cf396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top tokens per phase:\n",
      "No 'tokens' column found; skipping token frequency by phase.\n"
     ]
    }
   ],
   "source": [
    "if not df_inf.empty:\n",
    "    print(\"\\nTop tokens per phase:\")\n",
    "\n",
    "    # If tokens column isn't there, we can't compute token frequencies.\n",
    "    if \"tokens\" not in df_inf.columns:\n",
    "        print(\"No 'tokens' column found; skipping token frequency by phase.\")\n",
    "    else:\n",
    "        # Loop over each phase (early / peak / post).\n",
    "        for phase in df_inf[\"phase_temp\"].unique():\n",
    "            # Keep only rows in this phase.\n",
    "            phase_df = df_inf[df_inf[\"phase_temp\"] == phase]\n",
    "\n",
    "            # Flatten all token lists into one long list of tokens.\n",
    "            all_tokens = [\n",
    "                t\n",
    "                for toks in phase_df[\"tokens\"]\n",
    "                if isinstance(toks, (list, tuple))   # skip bad entries\n",
    "                for t in toks\n",
    "            ]\n",
    "\n",
    "            # Count token frequencies for this phase.\n",
    "            counts = Counter(all_tokens)\n",
    "            print(f\"\\nPhase: {phase}\")\n",
    "            print(counts.most_common(15))  # top 15 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2421dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average sentiment by phase:\n",
      "phase_temp\n",
      "early    0.371401\n",
      "Name: sentiment, dtype: float64\n",
      "\n",
      "Average sentiment by month (first 10 rows):\n",
      "month\n",
      "1970-01    0.371401\n",
      "Freq: M, Name: sentiment, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/k_ksjzq515d486qysdmsnrlr0000gn/T/ipykernel_36360/3668350134.py:39: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  .groupby(df_inf[\"created_utc\"].dt.to_period(\"M\"))[\"sentiment\"]\n"
     ]
    }
   ],
   "source": [
    "if not df_inf.empty:\n",
    "    # If clean_text isn't present, create a simple cleaned version of raw_text.\n",
    "    if \"clean_text\" not in df_inf.columns:\n",
    "        def clean_text_basic(text: str) -> str:\n",
    "            if not isinstance(text, str):\n",
    "                return \"\"\n",
    "            # Remove URLs.\n",
    "            text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "            # Lowercase.\n",
    "            text = text.lower()\n",
    "            # Remove punctuation.\n",
    "            text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "            # Collapse multiple spaces.\n",
    "            text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "            return text\n",
    "\n",
    "        df_inf[\"clean_text\"] = df_inf[\"raw_text\"].apply(clean_text_basic)\n",
    "\n",
    "    # Initialize VADER sentiment analyzer (gives Â± sentiment scores).\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def vader_compound(text: str) -> float:\n",
    "        # Return compound score in [-1, 1]; 0 for empty/non-string.\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return 0.0\n",
    "        return sia.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "    # Compute a sentiment score for each row based on clean_text.\n",
    "    df_inf[\"sentiment\"] = df_inf[\"clean_text\"].apply(vader_compound)\n",
    "\n",
    "    # Average sentiment for each phase.\n",
    "    sent_by_phase = df_inf.groupby(\"phase_temp\")[\"sentiment\"].mean().sort_index()\n",
    "    print(\"\\nAverage sentiment by phase:\")\n",
    "    print(sent_by_phase)\n",
    "\n",
    "    # Average sentiment by month (using month period of created_utc).\n",
    "    sent_by_month = (\n",
    "        df_inf\n",
    "        .groupby(df_inf[\"created_utc\"].dt.to_period(\"M\"))[\"sentiment\"]\n",
    "        .mean()\n",
    "        .rename_axis(index=\"month\")\n",
    "    )\n",
    "    print(\"\\nAverage sentiment by month (first 10 rows):\")\n",
    "    print(sent_by_month.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddd632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save updated TEST file with new columns \n",
    "\n",
    "# Simpler name for the processed test data\n",
    "out_path = cleaned_dir / \"reddit_test_with_phase.parquet\"\n",
    "\n",
    "df.to_parquet(out_path, engine=\"pyarrow\", index=False)\n",
    "\n",
    "print(\"\\nSaved updated TEST data with phase/is_inflation to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8134de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1970-01-01 00:00:01.643673217+00:00\n",
      "1   1970-01-01 00:00:01.643672497+00:00\n",
      "2   1970-01-01 00:00:01.643671641+00:00\n",
      "3   1970-01-01 00:00:01.643671106+00:00\n",
      "4   1970-01-01 00:00:01.643668802+00:00\n",
      "5   1970-01-01 00:00:01.643668324+00:00\n",
      "6   1970-01-01 00:00:01.643667109+00:00\n",
      "7   1970-01-01 00:00:01.643665886+00:00\n",
      "8   1970-01-01 00:00:01.643663882+00:00\n",
      "9   1970-01-01 00:00:01.643662973+00:00\n",
      "Name: created_utc, dtype: datetime64[ns, UTC]\n",
      "datetime64[ns, UTC]\n",
      "created_utc\n",
      "1970    10754\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Debug\n",
    "\n",
    "print(df_inf[\"created_utc\"].head(10))\n",
    "print(df_inf[\"created_utc\"].dtype)\n",
    "print(df_inf[\"created_utc\"].dt.year.value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
