{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba300b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ac006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic paths\n",
    "\n",
    "# If needed in a fresh environment, run once:\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# ---------- Paths ----------\n",
    "base_path = Path(\"/Users/apple/Desktop/30112_python/Scrape_Reddit\")\n",
    "cleaned_dir = base_path / \"scraped_data\"\n",
    "\n",
    "in_path = cleaned_dir / \"reddit_inflation_2020_2025_posts_and_comments_TEST_clean.parquet\"\n",
    "\n",
    "print(\"Loading:\", in_path)\n",
    "df = pd.read_parquet(in_path)\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "datetime_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Check datetime format\n",
    "print(\"\\n=== DATETIME DIAGNOSTIC ===\")\n",
    "print(\"created_utc dtype:\", df[\"created_utc\"].dtype)\n",
    "print(\"\\nFirst 10 timestamps:\")\n",
    "print(df[\"created_utc\"].head(10))\n",
    "\n",
    "# Check if year column exists and what it contains\n",
    "if \"year\" in df.columns:\n",
    "    print(\"\\nYear distribution (existing):\")\n",
    "    print(df[\"year\"].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"\\nNo 'year' column found - will be created from created_utc\")\n",
    "\n",
    "# FIXED: Ensure created_utc is properly formatted as datetime\n",
    "if not pd.api.types.is_datetime64_any_dtype(df[\"created_utc\"]):\n",
    "    print(\"\\nWARNING: created_utc is not datetime type. Converting...\")\n",
    "    # Try to convert - if it's already timestamps, use unit='s'\n",
    "    if pd.api.types.is_numeric_dtype(df[\"created_utc\"]):\n",
    "        df[\"created_utc\"] = pd.to_datetime(df[\"created_utc\"], unit=\"s\", utc=True)\n",
    "    else:\n",
    "        df[\"created_utc\"] = pd.to_datetime(df[\"created_utc\"], utc=True, errors=\"coerce\")\n",
    "    print(\"Conversion complete. New dtype:\", df[\"created_utc\"].dtype)\n",
    "    print(\"Sample converted values:\")\n",
    "    print(df[\"created_utc\"].head())\n",
    "\n",
    "print(\"\\n=== END DIAGNOSTIC ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0055bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Phase Labels\n",
    "# Updated with more realistic inflation phases based on actual timeline\n",
    "\n",
    "def assign_inflation_phase(dt: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Assign inflation phase based on actual US inflation timeline:\n",
    "    - Pre-inflation: 2020-2021 (low inflation, ~1-2%)\n",
    "    - Rising: Jan 2021 - Dec 2021 (inflation starts climbing, 1% -> 7%)\n",
    "    - Peak: 2022 - mid 2023 (high inflation, peaked at 9.1% June 2022)\n",
    "    - Cooling: Mid 2023 - 2025 (inflation declining, ~3-4%)\n",
    "    \"\"\"\n",
    "    if pd.isna(dt):\n",
    "        return \"unknown\"\n",
    "\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    \n",
    "    # Pre-inflation period (stable low inflation)\n",
    "    if year == 2020:\n",
    "        return \"pre_inflation\"\n",
    "    \n",
    "    # Rising inflation period (starting to climb)\n",
    "    elif year == 2021:\n",
    "        return \"rising\"\n",
    "    \n",
    "    # Peak inflation period\n",
    "    elif year == 2022:\n",
    "        return \"peak\"\n",
    "    \n",
    "    # Cooling period (inflation declining but still elevated)\n",
    "    elif year == 2023:\n",
    "        if month <= 6:\n",
    "            return \"peak\"  # First half of 2023 still elevated\n",
    "        else:\n",
    "            return \"cooling\"\n",
    "    \n",
    "    # 2024-2025: continued cooling\n",
    "    elif year >= 2024:\n",
    "        return \"cooling\"\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "# Apply phase assignment\n",
    "df[\"inflation_phase\"] = df[\"created_utc\"].apply(assign_inflation_phase)\n",
    "\n",
    "print(\"\\nInflation phase counts:\")\n",
    "print(df[\"inflation_phase\"].value_counts().sort_index())\n",
    "\n",
    "# Show date range for each phase\n",
    "print(\"\\nDate range by phase:\")\n",
    "for phase in df[\"inflation_phase\"].unique():\n",
    "    phase_df = df[df[\"inflation_phase\"] == phase]\n",
    "    if len(phase_df) > 0:\n",
    "        min_date = phase_df[\"created_utc\"].min()\n",
    "        max_date = phase_df[\"created_utc\"].max()\n",
    "        print(f\"{phase}: {min_date.date()} to {max_date.date()} ({len(phase_df):,} posts/comments)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53304818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword List and helper for is_inflation\n",
    "\n",
    "KEYWORDS = [\n",
    "    # Core inflation/econ\n",
    "    \"inflation\",\n",
    "    \"cost of living\",\n",
    "    \"cost-of-living\",\n",
    "    \"high cost of living\",\n",
    "    \"living costs\",\n",
    "    \"price increases\",\n",
    "    \"rising prices\",\n",
    "    \"cpi\",\n",
    "    \"consumer price index\",\n",
    "    \"interest rates\",\n",
    "    \"mortgage rates\",\n",
    "    \"fed\",\n",
    "    \"federal reserve\",\n",
    "    \"rate hike\",\n",
    "    \"rate hikes\",\n",
    "    \"rate increase\",\n",
    "    \"rate increases\",\n",
    "    # Everyday expenses\n",
    "    \"gas prices\",\n",
    "    \"gas price\",\n",
    "    \"grocery prices\",\n",
    "    \"grocery bill\",\n",
    "    \"food prices\",\n",
    "    \"food bill\",\n",
    "    \"rent increase\",\n",
    "    \"rent hike\",\n",
    "    \"higher rent\",\n",
    "    \"rent is too high\",\n",
    "    \"housing costs\",\n",
    "    \"housing affordability\",\n",
    "    \"property taxes\",\n",
    "    \"electric bill\",\n",
    "    \"electricity bill\",\n",
    "    \"energy bill\",\n",
    "    \"heating bill\",\n",
    "    \"gas bill\",\n",
    "    \"utility bills\",\n",
    "    \"utilities\",\n",
    "    # Income / strain\n",
    "    \"wage stagnation\",\n",
    "    \"wages not keeping up\",\n",
    "    \"real wages\",\n",
    "    \"paycheck to paycheck\",\n",
    "    \"making ends meet\",\n",
    "    \"can't afford\",\n",
    "    \"cannot afford\",\n",
    "]\n",
    "KEYWORDS_LOWER = [k.lower() for k in KEYWORDS]\n",
    "\n",
    "def text_matches_keywords(text: str) -> bool:\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    t = text.lower()\n",
    "    return any(k in t for k in KEYWORDS_LOWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build raw_text (fallback) and recompute is_inflation\n",
    "\n",
    "# raw_text should already exist from the cleaning step (title + body).\n",
    "# If not, create it here.\n",
    "if \"raw_text\" not in df.columns:\n",
    "    df[\"raw_text\"] = (\n",
    "        df[[\"title\", \"body\"]]\n",
    "        .fillna(\"\")\n",
    "        .agg(\" \".join, axis=1)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "df[\"is_inflation\"] = df[\"raw_text\"].apply(text_matches_keywords)\n",
    "\n",
    "print(\"is_inflation value counts:\")\n",
    "print(df[\"is_inflation\"].value_counts(dropna=False))\n",
    "\n",
    "# Manual quality check: print a few examples\n",
    "print(\"\\nSample inflation-related rows:\")\n",
    "if df[\"is_inflation\"].any():\n",
    "    sample_infl = df[df[\"is_inflation\"]].sample(\n",
    "        n=min(5, df[\"is_inflation\"].sum()), random_state=42\n",
    "    )\n",
    "    for _, row in sample_infl.iterrows():\n",
    "        print(\"----\")\n",
    "        print(row[\"created_utc\"], \"|\", row[\"subreddit\"], \"|\", row[\"type\"])\n",
    "        print(row[\"raw_text\"][:400], \"...\\n\")\n",
    "else:\n",
    "    print(\"No rows flagged as inflation-related in this TEST dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilot analysis (on TEST data)\n",
    "\n",
    "df_inf = df[df[\"is_inflation\"]].copy()\n",
    "print(\"\\nInflation-related rows:\", df_inf.shape[0])\n",
    "print(\"Date range:\", df_inf[\"created_utc\"].min(), \"to\", df_inf[\"created_utc\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_inf.empty:\n",
    "    # Group inflation-related rows by month (period 'M') and post type,\n",
    "    # count how many rows fall into each (month, type) combo.\n",
    "    monthly_counts = (\n",
    "        df_inf\n",
    "        .groupby([df_inf[\"created_utc\"].dt.to_period(\"M\"), \"type\"])\n",
    "        .size()                      # number of rows in each group\n",
    "        .unstack(fill_value=0)       # turn 'type' into columns\n",
    "        .rename_axis(index=\"month\")  # label the index as 'month'\n",
    "    )\n",
    "\n",
    "    print(\"\\nMonthly counts (first 20 rows):\")\n",
    "    print(monthly_counts.head(20))\n",
    "    \n",
    "    print(\"\\nMonthly counts (last 20 rows):\")\n",
    "    print(monthly_counts.tail(20))\n",
    "\n",
    "    # Group by phase and type to see how many posts/comments per phase.\n",
    "    phase_counts = (\n",
    "        df_inf\n",
    "        .groupby([\"inflation_phase\", \"type\"])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "\n",
    "    print(\"\\nCounts by inflation phase and type:\")\n",
    "    print(phase_counts)\n",
    "else:\n",
    "    print(\"No inflation-related rows; skipping counts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795cf396",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_inf.empty:\n",
    "    print(\"\\nTop tokens per phase:\")\n",
    "\n",
    "    # If tokens column isn't there, we can't compute token frequencies.\n",
    "    if \"tokens\" not in df_inf.columns:\n",
    "        print(\"No 'tokens' column found; skipping token frequency by phase.\")\n",
    "    else:\n",
    "        # Loop over each phase.\n",
    "        for phase in sorted(df_inf[\"inflation_phase\"].unique()):\n",
    "            # Keep only rows in this phase.\n",
    "            phase_df = df_inf[df_inf[\"inflation_phase\"] == phase]\n",
    "\n",
    "            # Flatten all token lists into one long list of tokens.\n",
    "            all_tokens = [\n",
    "                t\n",
    "                for toks in phase_df[\"tokens\"]\n",
    "                if isinstance(toks, (list, tuple))   # skip bad entries\n",
    "                for t in toks\n",
    "            ]\n",
    "\n",
    "            # Count token frequencies for this phase.\n",
    "            counts = Counter(all_tokens)\n",
    "            print(f\"\\nPhase: {phase} ({len(phase_df):,} posts/comments)\")\n",
    "            print(counts.most_common(15))  # top 15 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_inf.empty:\n",
    "    # If clean_text isn't present, create a simple cleaned version of raw_text.\n",
    "    if \"clean_text\" not in df_inf.columns:\n",
    "        def clean_text_basic(text: str) -> str:\n",
    "            if not isinstance(text, str):\n",
    "                return \"\"\n",
    "            # Remove URLs.\n",
    "            text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "            # Lowercase.\n",
    "            text = text.lower()\n",
    "            # Remove punctuation.\n",
    "            text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "            # Collapse multiple spaces.\n",
    "            text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "            return text\n",
    "\n",
    "        df_inf[\"clean_text\"] = df_inf[\"raw_text\"].apply(clean_text_basic)\n",
    "\n",
    "    # Initialize VADER sentiment analyzer (gives Â± sentiment scores).\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def vader_compound(text: str) -> float:\n",
    "        # Return compound score in [-1, 1]; 0 for empty/non-string.\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return 0.0\n",
    "        return sia.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "    # Compute a sentiment score for each row based on clean_text.\n",
    "    df_inf[\"sentiment\"] = df_inf[\"clean_text\"].apply(vader_compound)\n",
    "\n",
    "    # Average sentiment for each phase.\n",
    "    sent_by_phase = df_inf.groupby(\"inflation_phase\")[\"sentiment\"].mean().sort_index()\n",
    "    print(\"\\nAverage sentiment by phase:\")\n",
    "    print(sent_by_phase)\n",
    "\n",
    "    # Average sentiment by month (using month period of created_utc).\n",
    "    sent_by_month = (\n",
    "        df_inf\n",
    "        .groupby(df_inf[\"created_utc\"].dt.to_period(\"M\"))[\"sentiment\"]\n",
    "        .mean()\n",
    "        .rename_axis(index=\"month\")\n",
    "    )\n",
    "    print(\"\\nAverage sentiment by month (first 20 rows):\")\n",
    "    print(sent_by_month.head(20))\n",
    "    print(\"\\nAverage sentiment by month (last 20 rows):\")\n",
    "    print(sent_by_month.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddd632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated TEST file with new columns\n",
    "\n",
    "out_path = cleaned_dir / \"reddit_test_with_phase.parquet\"\n",
    "\n",
    "df.to_parquet(out_path, engine=\"pyarrow\", index=False)\n",
    "\n",
    "print(\"\\nSaved updated TEST data with inflation_phase/is_inflation to:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
