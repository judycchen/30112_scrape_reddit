{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b18703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f39d8",
   "metadata": {},
   "source": [
    "### Loading scraped raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fe18d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet path: /Users/apple/Desktop/30112_python/Scrape_Reddit/reddit_inflation_2020_2025_posts_and_comments_TEST.parquet\n",
      "Exists? True\n",
      "Original shape: (35023, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>submission</td>\n",
       "      <td>shg9hy</td>\n",
       "      <td>shg9hy</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Mortgage options for buying house that you won...</td>\n",
       "      <td>If a friend is living with me rent free, can t...</td>\n",
       "      <td>1643673217</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>submission</td>\n",
       "      <td>shg01r</td>\n",
       "      <td>shg01r</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Invest or pay extra on student loans?</td>\n",
       "      <td>Hi personal finance,\\n\\nI'm trying to decide w...</td>\n",
       "      <td>1643672497</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submission</td>\n",
       "      <td>shfohd</td>\n",
       "      <td>shfohd</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>New HVAC Rebates, don't want to miss anything.</td>\n",
       "      <td>Location: Ohio\\n\\nPurchased a Bryant Evolution...</td>\n",
       "      <td>1643671641</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>submission</td>\n",
       "      <td>shfgx2</td>\n",
       "      <td>shfgx2</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Which financial decision benefits me long term?</td>\n",
       "      <td>Hello,\\n\\nI got two different financial decisi...</td>\n",
       "      <td>1643671106</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submission</td>\n",
       "      <td>shej98</td>\n",
       "      <td>shej98</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>File an amendment now?</td>\n",
       "      <td>I just submitted my federal return using credi...</td>\n",
       "      <td>1643668802</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type      id link_id parent_id        subreddit  \\\n",
       "0  submission  shg9hy  shg9hy      None  personalfinance   \n",
       "1  submission  shg01r  shg01r      None  personalfinance   \n",
       "2  submission  shfohd  shfohd      None  personalfinance   \n",
       "3  submission  shfgx2  shfgx2      None  personalfinance   \n",
       "4  submission  shej98  shej98      None  personalfinance   \n",
       "\n",
       "                                               title  \\\n",
       "0  Mortgage options for buying house that you won...   \n",
       "1              Invest or pay extra on student loans?   \n",
       "2     New HVAC Rebates, don't want to miss anything.   \n",
       "3    Which financial decision benefits me long term?   \n",
       "4                             File an amendment now?   \n",
       "\n",
       "                                                body  created_utc  score  \\\n",
       "0  If a friend is living with me rent free, can t...   1643673217      1   \n",
       "1  Hi personal finance,\\n\\nI'm trying to decide w...   1643672497      1   \n",
       "2  Location: Ohio\\n\\nPurchased a Bryant Evolution...   1643671641      1   \n",
       "3  Hello,\\n\\nI got two different financial decisi...   1643671106      1   \n",
       "4  I just submitted my federal return using credi...   1643668802      1   \n",
       "\n",
       "   num_comments  \n",
       "0           6.0  \n",
       "1           6.0  \n",
       "2           0.0  \n",
       "3          14.0  \n",
       "4           4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load standardize metadata\n",
    "\n",
    "# Base folder where the Parquet file lives\n",
    "BASE_PATH = Path(\"/Users/apple/Desktop/30112_python/Scrape_Reddit\")\n",
    "\n",
    "# Parquet file produced by the Arctic Shift scraping script (TEST mode)\n",
    "parquet_path = BASE_PATH / \"reddit_inflation_2020_2025_posts_and_comments_TEST.parquet\"\n",
    "\n",
    "# Sanity check: make sure the file exists before loading\n",
    "print(\"Parquet path:\", parquet_path)\n",
    "print(\"Exists?\", parquet_path.exists())\n",
    "\n",
    "# Load the full Reddit dataset (posts + comments)\n",
    "df = pd.read_parquet(parquet_path)\n",
    "print(\"Original shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc7603",
   "metadata": {},
   "source": [
    "### Cleaning missing and unmeaningful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11452d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After column selection: (35023, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>submission</td>\n",
       "      <td>shg9hy</td>\n",
       "      <td>shg9hy</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Mortgage options for buying house that you won...</td>\n",
       "      <td>If a friend is living with me rent free, can t...</td>\n",
       "      <td>2022-01-31 23:53:37+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>submission</td>\n",
       "      <td>shg01r</td>\n",
       "      <td>shg01r</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Invest or pay extra on student loans?</td>\n",
       "      <td>Hi personal finance,\\n\\nI'm trying to decide w...</td>\n",
       "      <td>2022-01-31 23:41:37+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submission</td>\n",
       "      <td>shfohd</td>\n",
       "      <td>shfohd</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>New HVAC Rebates, don't want to miss anything.</td>\n",
       "      <td>Location: Ohio\\n\\nPurchased a Bryant Evolution...</td>\n",
       "      <td>2022-01-31 23:27:21+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>submission</td>\n",
       "      <td>shfgx2</td>\n",
       "      <td>shfgx2</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Which financial decision benefits me long term?</td>\n",
       "      <td>Hello,\\n\\nI got two different financial decisi...</td>\n",
       "      <td>2022-01-31 23:18:26+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submission</td>\n",
       "      <td>shej98</td>\n",
       "      <td>shej98</td>\n",
       "      <td>None</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>File an amendment now?</td>\n",
       "      <td>I just submitted my federal return using credi...</td>\n",
       "      <td>2022-01-31 22:40:02+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type      id link_id parent_id        subreddit  \\\n",
       "0  submission  shg9hy  shg9hy      None  personalfinance   \n",
       "1  submission  shg01r  shg01r      None  personalfinance   \n",
       "2  submission  shfohd  shfohd      None  personalfinance   \n",
       "3  submission  shfgx2  shfgx2      None  personalfinance   \n",
       "4  submission  shej98  shej98      None  personalfinance   \n",
       "\n",
       "                                               title  \\\n",
       "0  Mortgage options for buying house that you won...   \n",
       "1              Invest or pay extra on student loans?   \n",
       "2     New HVAC Rebates, don't want to miss anything.   \n",
       "3    Which financial decision benefits me long term?   \n",
       "4                             File an amendment now?   \n",
       "\n",
       "                                                body  \\\n",
       "0  If a friend is living with me rent free, can t...   \n",
       "1  Hi personal finance,\\n\\nI'm trying to decide w...   \n",
       "2  Location: Ohio\\n\\nPurchased a Bryant Evolution...   \n",
       "3  Hello,\\n\\nI got two different financial decisi...   \n",
       "4  I just submitted my federal return using credi...   \n",
       "\n",
       "                created_utc  score  num_comments  \n",
       "0 2022-01-31 23:53:37+00:00      1           6.0  \n",
       "1 2022-01-31 23:41:37+00:00      1           6.0  \n",
       "2 2022-01-31 23:27:21+00:00      1           0.0  \n",
       "3 2022-01-31 23:18:26+00:00      1          14.0  \n",
       "4 2022-01-31 22:40:02+00:00      1           4.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the columns we actually need for analysis.\n",
    "# If some are missing (e.g., num_comments on comments), we just keep the ones that exist.\n",
    "EXPECTED_COLS = [\n",
    "    \"type\",          # \"submission\" or \"comment\"\n",
    "    \"id\",\n",
    "    \"link_id\",\n",
    "    \"parent_id\",\n",
    "    \"subreddit\",\n",
    "    \"title\",\n",
    "    \"body\",          # main text for comments, selftext for posts\n",
    "    \"created_utc\",   # timestamp (epoch seconds)\n",
    "    \"score\",\n",
    "    \"num_comments\",  # only meaningful for submissions\n",
    "]\n",
    "\n",
    "keep_cols = [c for c in EXPECTED_COLS if c in df.columns]\n",
    "df = df[keep_cols].copy()\n",
    "print(\"After column selection:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694d81e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-31 23:53:37+00:00</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-31 23:41:37+00:00</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-31 23:27:21+00:00</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-31 23:18:26+00:00</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-31 22:40:02+00:00</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_utc        date  year  month\n",
       "0 2022-01-31 23:53:37+00:00  2022-01-31  2022      1\n",
       "1 2022-01-31 23:41:37+00:00  2022-01-31  2022      1\n",
       "2 2022-01-31 23:27:21+00:00  2022-01-31  2022      1\n",
       "3 2022-01-31 23:18:26+00:00  2022-01-31  2022      1\n",
       "4 2022-01-31 22:40:02+00:00  2022-01-31  2022      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert created_utc (epoch seconds) into a timezoneâ€‘aware datetime.\n",
    "# Then add year/month/date columns for grouping later.\n",
    "df[\"created_utc\"] = pd.to_datetime(df[\"created_utc\"], unit=\"s\", utc=True)\n",
    "df[\"date\"] = df[\"created_utc\"].dt.date\n",
    "df[\"year\"] = df[\"created_utc\"].dt.year\n",
    "df[\"month\"] = df[\"created_utc\"].dt.month\n",
    "\n",
    "df[[\"created_utc\", \"date\", \"year\", \"month\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8dc50f",
   "metadata": {},
   "source": [
    "### Text cleaning & Preprocessing\n",
    "(Organizing & Tokenizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5fdf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Run these once in a fresh environment (comment them out afterwards).\n",
    "# They download NLTK data files to your machine.\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# English stopword list (e.g., \"the\", \"and\", \"is\")\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Translation table to remove punctuation characters\n",
    "PUNCT_TABLE = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "def clean_text_basic(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Basic text cleaner:\n",
    "    - Handle missing values\n",
    "    - Remove URLs\n",
    "    - Lowercase text\n",
    "    - Remove punctuation\n",
    "    - Collapse extra whitespace\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Remove URLs (http..., www...)\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    # Lowercase everything\n",
    "    text = text.lower()\n",
    "    # Remove punctuation characters\n",
    "    text = text.translate(PUNCT_TABLE)\n",
    "    # Replace multiple spaces/newlines with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize_and_remove_stopwords(text: str):\n",
    "    \"\"\"\n",
    "    Tokenize a cleaned text string, then:\n",
    "    - Keep only alphabetic tokens (no numbers, no leftover punctuation)\n",
    "    - Drop stopwords like \"the\", \"and\", etc.\n",
    "    Returns a list of tokens.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7dfac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>submission</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>2022-01-31 23:53:37+00:00</td>\n",
       "      <td>Mortgage options for buying house that you won...</td>\n",
       "      <td>mortgage options for buying house that you won...</td>\n",
       "      <td>[mortgage, options, buying, house, wont, live,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>submission</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>2022-01-31 23:41:37+00:00</td>\n",
       "      <td>Invest or pay extra on student loans? Hi perso...</td>\n",
       "      <td>invest or pay extra on student loans hi person...</td>\n",
       "      <td>[invest, pay, extra, student, loans, hi, perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submission</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>2022-01-31 23:27:21+00:00</td>\n",
       "      <td>New HVAC Rebates, don't want to miss anything....</td>\n",
       "      <td>new hvac rebates dont want to miss anything lo...</td>\n",
       "      <td>[new, hvac, rebates, dont, want, miss, anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>submission</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>2022-01-31 23:18:26+00:00</td>\n",
       "      <td>Which financial decision benefits me long term...</td>\n",
       "      <td>which financial decision benefits me long term...</td>\n",
       "      <td>[financial, decision, benefits, long, term, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submission</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>2022-01-31 22:40:02+00:00</td>\n",
       "      <td>File an amendment now? I just submitted my fed...</td>\n",
       "      <td>file an amendment now i just submitted my fede...</td>\n",
       "      <td>[file, amendment, submitted, federal, return, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type        subreddit               created_utc  \\\n",
       "0  submission  personalfinance 2022-01-31 23:53:37+00:00   \n",
       "1  submission  personalfinance 2022-01-31 23:41:37+00:00   \n",
       "2  submission  personalfinance 2022-01-31 23:27:21+00:00   \n",
       "3  submission  personalfinance 2022-01-31 23:18:26+00:00   \n",
       "4  submission  personalfinance 2022-01-31 22:40:02+00:00   \n",
       "\n",
       "                                            raw_text  \\\n",
       "0  Mortgage options for buying house that you won...   \n",
       "1  Invest or pay extra on student loans? Hi perso...   \n",
       "2  New HVAC Rebates, don't want to miss anything....   \n",
       "3  Which financial decision benefits me long term...   \n",
       "4  File an amendment now? I just submitted my fed...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  mortgage options for buying house that you won...   \n",
       "1  invest or pay extra on student loans hi person...   \n",
       "2  new hvac rebates dont want to miss anything lo...   \n",
       "3  which financial decision benefits me long term...   \n",
       "4  file an amendment now i just submitted my fede...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [mortgage, options, buying, house, wont, live,...  \n",
       "1  [invest, pay, extra, student, loans, hi, perso...  \n",
       "2  [new, hvac, rebates, dont, want, miss, anythin...  \n",
       "3  [financial, decision, benefits, long, term, he...  \n",
       "4  [file, amendment, submitted, federal, return, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine title + body into a single raw_text field so we always\n",
    "# have all the context for a post or comment in one place.\n",
    "# (For comments, title will be empty; for posts, body is the selftext.)\n",
    "df[\"raw_text\"] = (\n",
    "    df[[\"title\", \"body\"]]\n",
    "    .fillna(\"\")         # replace NaN with empty strings\n",
    "    .agg(\" \".join, axis=1)  # join title and body with a space\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Apply the cleaner to get a normalized string version.\n",
    "df[\"clean_text\"] = df[\"raw_text\"].apply(clean_text_basic)\n",
    "\n",
    "# Tokenize into a list of words (no stopwords, no punctuation).\n",
    "df[\"tokens\"] = df[\"clean_text\"].apply(tokenize_and_remove_stopwords)\n",
    "\n",
    "# Quick peek at the processed columns to make sure things look reasonable.\n",
    "df[[\"type\", \"subreddit\", \"created_utc\", \"raw_text\", \"clean_text\", \"tokens\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dcde1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned data to: /Users/apple/Desktop/30112_python/Scrape_Reddit/scraped_data/reddit_inflation_2020_2025_posts_and_comments_TEST_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save as Parquet (recommended for speed/size)\n",
    "\n",
    "out_path = BASE_PATH / \"scraped_data\" / \"reddit_inflation_2020_2025_posts_and_comments_TEST_clean.parquet\"\n",
    "\n",
    "# Create folders if they don't exist\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df.to_parquet(out_path, engine=\"pyarrow\", index=False)\n",
    "print(\"Saved cleaned data to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
